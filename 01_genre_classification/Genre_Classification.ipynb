{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pikapikasecoy/Music-Genre-Classification-with-GTZAN-Dataset/blob/main/MSDS699_FinalProject_AprilQianyunLi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BMJ97ahB2up"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJ15O7nwB2uq",
    "outputId": "fbdb77e0-60d1-4756-ec89-9f88de06b307"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   category_encoders          import *\n",
    "from   sklearn.compose            import *\n",
    "from   sklearn.ensemble           import *\n",
    "from   sklearn.experimental       import enable_iterative_imputer\n",
    "from   sklearn.impute             import *\n",
    "from   sklearn.linear_model       import *\n",
    "from   sklearn.metrics            import * \n",
    "from   sklearn.pipeline           import Pipeline\n",
    "from   sklearn.preprocessing      import *\n",
    "from   sklearn.tree               import *\n",
    "from   sklearn.model_selection    import *\n",
    "from   sklearn.base               import BaseEstimator\n",
    "from   sklearn.decomposition      import PCA\n",
    "from   sklearn.inspection         import permutation_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJIXE2BpB2uq"
   },
   "source": [
    "# 1. Data and Target Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_Y-e8zhB2uq"
   },
   "source": [
    "* ### Data Description\n",
    "    URL: https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification\n",
    "    \n",
    "    A collection of 10 genres with 100 audio files each (balanced), containing features of the audio files, with a mean and variance computed over multiple features that can be extracted from an audio file for each song. The main music features are described as below:\n",
    "        \n",
    "    * chroma_stft: chromagram of soundtrack, is defined to differ different pitches of music\n",
    "    * rms: root-mean-square (RMS) value for each frame from a spectrogram\n",
    "    * spectral_centroid: the center of ‘gravity’ of the spectrum, each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame\n",
    "    * spectral_bandwidth: the second central moment of the spectrum\n",
    "    * rolloff: The roll-off frequency is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below.\n",
    "    * harmony: simultaneously occurring frequencies, pitches (tones, notes), or chords. \n",
    "    * tempo: the speed of music being played\n",
    "    * mfcc: the mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency, and Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an MFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYzIiYTuB2ur"
   },
   "source": [
    "* ### Analytics Goal\n",
    "    Genre Classification with music features extracted from audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J46mqCwCB2ur"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/features_30_sec.csv\")\n",
    "\n",
    "X = data.drop(columns=[\"filename\", \"length\", \"label\"])\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2kJrppwB2us",
    "outputId": "501c0a8b-ea82-4a90-f046-c36ae10eef2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 57), (1000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "QeynaCHOB2us",
    "outputId": "f673757a-0b13-400a-8ff8-5f19e6dc08c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.352063</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>2008.149458</td>\n",
       "      <td>282174.689224</td>\n",
       "      <td>2106.541053</td>\n",
       "      <td>88609.749506</td>\n",
       "      <td>4253.557033</td>\n",
       "      <td>1.222421e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.789867</td>\n",
       "      <td>45.050526</td>\n",
       "      <td>-13.289984</td>\n",
       "      <td>41.754955</td>\n",
       "      <td>2.484145</td>\n",
       "      <td>36.778877</td>\n",
       "      <td>-6.713265</td>\n",
       "      <td>54.866825</td>\n",
       "      <td>-1.193787</td>\n",
       "      <td>49.950665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.398687</td>\n",
       "      <td>0.075086</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>2006.843354</td>\n",
       "      <td>182114.709510</td>\n",
       "      <td>2068.942009</td>\n",
       "      <td>82426.016726</td>\n",
       "      <td>4149.338328</td>\n",
       "      <td>1.046621e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.739020</td>\n",
       "      <td>33.851742</td>\n",
       "      <td>-10.848309</td>\n",
       "      <td>39.395096</td>\n",
       "      <td>1.881229</td>\n",
       "      <td>32.010040</td>\n",
       "      <td>-7.461491</td>\n",
       "      <td>39.196327</td>\n",
       "      <td>-2.795338</td>\n",
       "      <td>31.773624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.432142</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2077.526598</td>\n",
       "      <td>231657.968040</td>\n",
       "      <td>1927.293153</td>\n",
       "      <td>74717.124394</td>\n",
       "      <td>4031.405321</td>\n",
       "      <td>8.042154e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.838090</td>\n",
       "      <td>33.597008</td>\n",
       "      <td>-12.845291</td>\n",
       "      <td>36.367264</td>\n",
       "      <td>3.440978</td>\n",
       "      <td>36.001110</td>\n",
       "      <td>-12.588070</td>\n",
       "      <td>42.502201</td>\n",
       "      <td>-2.106337</td>\n",
       "      <td>29.865515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.362485</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>1398.699344</td>\n",
       "      <td>240318.731073</td>\n",
       "      <td>1818.450280</td>\n",
       "      <td>109090.207161</td>\n",
       "      <td>3015.631004</td>\n",
       "      <td>1.332712e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.812176</td>\n",
       "      <td>46.324894</td>\n",
       "      <td>-4.416050</td>\n",
       "      <td>43.583942</td>\n",
       "      <td>1.556207</td>\n",
       "      <td>34.331261</td>\n",
       "      <td>-5.041897</td>\n",
       "      <td>47.227180</td>\n",
       "      <td>-3.590644</td>\n",
       "      <td>41.299088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.358401</td>\n",
       "      <td>0.085884</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1609.795082</td>\n",
       "      <td>422203.216152</td>\n",
       "      <td>1797.213044</td>\n",
       "      <td>120115.632927</td>\n",
       "      <td>3246.908930</td>\n",
       "      <td>1.753476e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.794104</td>\n",
       "      <td>59.167755</td>\n",
       "      <td>-7.069775</td>\n",
       "      <td>73.760391</td>\n",
       "      <td>0.028346</td>\n",
       "      <td>76.504326</td>\n",
       "      <td>-2.025783</td>\n",
       "      <td>72.189316</td>\n",
       "      <td>1.155239</td>\n",
       "      <td>49.662510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "995          0.352063         0.080487  0.079486  0.000345   \n",
       "996          0.398687         0.075086  0.076458  0.000588   \n",
       "997          0.432142         0.075268  0.081651  0.000322   \n",
       "998          0.362485         0.091506  0.083860  0.001211   \n",
       "999          0.358401         0.085884  0.054454  0.000336   \n",
       "\n",
       "     spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "995             2008.149458          282174.689224              2106.541053   \n",
       "996             2006.843354          182114.709510              2068.942009   \n",
       "997             2077.526598          231657.968040              1927.293153   \n",
       "998             1398.699344          240318.731073              1818.450280   \n",
       "999             1609.795082          422203.216152              1797.213044   \n",
       "\n",
       "     spectral_bandwidth_var  rolloff_mean   rolloff_var  ...  mfcc16_mean  \\\n",
       "995            88609.749506   4253.557033  1.222421e+06  ...     1.789867   \n",
       "996            82426.016726   4149.338328  1.046621e+06  ...     3.739020   \n",
       "997            74717.124394   4031.405321  8.042154e+05  ...     1.838090   \n",
       "998           109090.207161   3015.631004  1.332712e+06  ...    -2.812176   \n",
       "999           120115.632927   3246.908930  1.753476e+06  ...     1.794104   \n",
       "\n",
       "     mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  \\\n",
       "995   45.050526   -13.289984   41.754955     2.484145   36.778877   \n",
       "996   33.851742   -10.848309   39.395096     1.881229   32.010040   \n",
       "997   33.597008   -12.845291   36.367264     3.440978   36.001110   \n",
       "998   46.324894    -4.416050   43.583942     1.556207   34.331261   \n",
       "999   59.167755    -7.069775   73.760391     0.028346   76.504326   \n",
       "\n",
       "     mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \n",
       "995    -6.713265   54.866825    -1.193787   49.950665  \n",
       "996    -7.461491   39.196327    -2.795338   31.773624  \n",
       "997   -12.588070   42.502201    -2.106337   29.865515  \n",
       "998    -5.041897   47.227180    -3.590644   41.299088  \n",
       "999    -2.025783   72.189316     1.155239   49.662510  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGCiHNoyB2ut"
   },
   "source": [
    "# 2. Feature Engineering and Target Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSKZkBcPB2ut"
   },
   "source": [
    "### 2.1 Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2qTOWSgB2ut",
    "outputId": "e9cac3a1-b0f3-4e6a-9816-ffb62fdb4301"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xveIregrB2uu"
   },
   "source": [
    "### 2.2 Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI9y6V0SB2uu"
   },
   "source": [
    "* Standardize Features\n",
    "* Transform Numerical Features to Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DzVJ4kunB2uu"
   },
   "outputs": [],
   "source": [
    "pipe_preprocessing = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                               (\"transformer\", QuantileTransformer(output_distribution='normal'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r_128nuB2uu"
   },
   "source": [
    "### 2.3 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zF7F_0haB2uv"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fWHKKSNVB2uv"
   },
   "outputs": [],
   "source": [
    "X_train_valid, X_valid, y_train_valid, y_valid = train_test_split(X_train, y_train,\n",
    "                                                                  train_size=0.8, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPDDR1NSB2uv",
    "outputId": "91320066-bf0f-40eb-b5de-12e8ff5e8701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chroma_stft_mean0.054 ± 0.016\n",
      "mfcc5_var0.026 ± 0.010\n",
      "mfcc6_mean0.025 ± 0.012\n",
      "mfcc12_mean0.021 ± 0.009\n",
      "chroma_stft_var0.021 ± 0.011\n",
      "mfcc7_mean0.021 ± 0.006\n",
      "rolloff_var0.019 ± 0.007\n",
      "mfcc4_mean0.018 ± 0.008\n",
      "mfcc13_mean0.017 ± 0.007\n",
      "mfcc8_mean0.015 ± 0.008\n",
      "mfcc9_mean0.014 ± 0.007\n",
      "mfcc8_var0.014 ± 0.011\n",
      "mfcc4_var0.013 ± 0.009\n",
      "mfcc6_var0.012 ± 0.011\n",
      "zero_crossing_rate_mean0.012 ± 0.008\n",
      "mfcc1_mean0.012 ± 0.008\n",
      "mfcc2_var0.012 ± 0.006\n",
      "harmony_var0.011 ± 0.010\n",
      "harmony_mean0.011 ± 0.008\n",
      "mfcc3_var0.011 ± 0.008\n",
      "mfcc17_mean0.010 ± 0.008\n",
      "mfcc3_mean0.009 ± 0.007\n",
      "spectral_bandwidth_var0.009 ± 0.010\n",
      "tempo   0.009 ± 0.005\n",
      "perceptr_var0.009 ± 0.011\n",
      "rms_mean0.009 ± 0.011\n",
      "mfcc14_mean0.009 ± 0.006\n",
      "mfcc15_mean0.007 ± 0.005\n",
      "mfcc10_var0.007 ± 0.011\n",
      "spectral_bandwidth_mean0.007 ± 0.007\n",
      "mfcc20_var0.007 ± 0.009\n",
      "mfcc19_var0.007 ± 0.004\n",
      "mfcc1_var0.007 ± 0.006\n",
      "mfcc14_var0.006 ± 0.003\n",
      "mfcc2_mean0.005 ± 0.005\n",
      "mfcc7_var0.005 ± 0.006\n",
      "zero_crossing_rate_var0.004 ± 0.006\n",
      "mfcc5_mean0.004 ± 0.007\n",
      "mfcc11_mean0.004 ± 0.006\n",
      "spectral_centroid_mean0.004 ± 0.012\n",
      "rolloff_mean0.003 ± 0.010\n",
      "mfcc16_mean0.002 ± 0.005\n",
      "mfcc13_var0.002 ± 0.006\n",
      "mfcc9_var0.001 ± 0.005\n",
      "perceptr_mean0.001 ± 0.006\n",
      "spectral_centroid_var0.001 ± 0.009\n",
      "mfcc10_mean0.001 ± 0.009\n",
      "mfcc18_mean0.001 ± 0.005\n",
      "mfcc19_mean0.000 ± 0.005\n",
      "mfcc11_var-0.000 ± 0.006\n",
      "mfcc20_mean-0.000 ± 0.006\n",
      "rms_var -0.002 ± 0.007\n",
      "mfcc17_var-0.002 ± 0.004\n",
      "mfcc12_var-0.002 ± 0.004\n",
      "mfcc15_var-0.003 ± 0.004\n",
      "mfcc16_var-0.004 ± 0.005\n",
      "mfcc18_var-0.007 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "pipe_test = Pipeline([('preprocessing', pipe_preprocessing),\n",
    "                      ('rf', RandomForestClassifier())])\n",
    "pipe_test.fit(X_train_valid, y_train_valid)\n",
    "r = permutation_importance(pipe_test,\n",
    "                           X_valid,\n",
    "                           y_valid,\n",
    "                           n_repeats=20,\n",
    "                           random_state=7)\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X_train_valid.columns[i]:<8}\"\n",
    "          f\"{r.importances_mean[i]:.3f}\"\n",
    "          f\" ± {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsy50vcpB2uw",
    "outputId": "45773260-e403-4258-9fa9-7c069b104bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balacend Accuracy Score with 20-splits cross validation:  0.692\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=20, shuffle=True, random_state=7)\n",
    "bas_test = cross_val_score(pipe_test, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "mean_bas_test = np.mean(mean_bas_test)\n",
    "print(f\"Mean Balacend Accuracy Score with 20-splits cross validation: {mean_bas_test: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyinWwwgB2uw"
   },
   "source": [
    "As we can see from the analysis of feature importance, even the most important feature has the importance only about 0.05, but the accuracy score of our model is actually not bad, which indicates our features do make contributions to the classification, but not with their individual contribution, some of them could probably have high codependence.\n",
    "If so, then the result of importance can not be trusted.\n",
    "\n",
    "Then we will apply PCA to our model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSKwyO7NB2uw",
    "outputId": "2a988d41-b92d-4da1-ca23-bafaa5a102ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balacend Accuracy Score with 20-splits cross validation:  0.692\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA() requires standardization\n",
    "pca = PCA()\n",
    "rf = RandomForestClassifier()\n",
    "pipe_pca = Pipeline([('preprocessing', pipe_preprocessing), ('pca', pca),\n",
    "                     ('rf', rf)])\n",
    "bas_pca = cross_val_score(pipe_pca, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "mean_bas_pca = np.mean(mean_bas_test)\n",
    "print(f\"Mean Balacend Accuracy Score with 20-splits cross validation: {mean_bas_pca: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Qojhp-oB2ux",
    "outputId": "d725f901-9eb2-4b3a-a7cf-7b0a043b8e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component #0: 26.67%\n",
      "Component #1: 16.84%\n",
      "Component #2: 10.26%\n",
      "Component #3:  7.38%\n",
      "Component #4:  5.19%\n",
      "Component #5:  3.74%\n",
      "Component #6:  3.05%\n",
      "Component #7:  2.60%\n",
      "Component #8:  2.13%\n",
      "Component #9:  1.71%\n",
      "Component #10:  1.55%\n",
      "Component #11:  1.49%\n",
      "Component #12:  1.10%\n",
      "Component #13:  1.07%\n",
      "Component #14:  0.98%\n",
      "Component #15:  0.91%\n",
      "Component #16:  0.82%\n",
      "Component #17:  0.74%\n",
      "Component #18:  0.70%\n",
      "Component #19:  0.65%\n",
      "Component #20:  0.61%\n",
      "Component #21:  0.54%\n",
      "Component #22:  0.54%\n",
      "Component #23:  0.51%\n",
      "Component #24:  0.48%\n",
      "Component #25:  0.46%\n",
      "Component #26:  0.46%\n",
      "Component #27:  0.42%\n",
      "Component #28:  0.41%\n",
      "Component #29:  0.40%\n",
      "Component #30:  0.39%\n",
      "Component #31:  0.38%\n",
      "Component #32:  0.36%\n",
      "Component #33:  0.35%\n",
      "Component #34:  0.33%\n",
      "Component #35:  0.32%\n",
      "Component #36:  0.31%\n",
      "Component #37:  0.29%\n",
      "Component #38:  0.28%\n",
      "Component #39:  0.27%\n",
      "Component #40:  0.26%\n",
      "Component #41:  0.25%\n",
      "Component #42:  0.23%\n",
      "Component #43:  0.21%\n",
      "Component #44:  0.21%\n",
      "Component #45:  0.20%\n",
      "Component #46:  0.19%\n",
      "Component #47:  0.18%\n",
      "Component #48:  0.15%\n",
      "Component #49:  0.13%\n",
      "Component #50:  0.09%\n",
      "Component #51:  0.07%\n",
      "Component #52:  0.06%\n",
      "Component #53:  0.05%\n",
      "Component #54:  0.03%\n",
      "Component #55:  0.02%\n",
      "Component #56:  0.01%\n"
     ]
    }
   ],
   "source": [
    "pipe_pca.fit(X_train_valid, y_train_valid)\n",
    "for i, r in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"Component #{i}: {r:>6.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYl8IiYFB2ux"
   },
   "source": [
    "After we applied PCA, we find that there are only about 13 components can explain more than 1% variance, and the accuracy score does not change, it's worth to try if we can simplify the model from 57 features to 13 components, which will improve the efficiency of random forest a lot.\n",
    "\n",
    "so we will check the influence of dropping insignificant components first, and after dropping those insignificant components, the accuracy score does not change too much, so we can just go ahead with 13 PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFpkddVJB2ux",
    "outputId": "72bfffad-831e-4fd7-d25f-a9abf925abc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balacend Accuracy Score with 20-splits cross validation:  0.692\n"
     ]
    }
   ],
   "source": [
    "# check the change of accuracy score with dropping insignificant PCA components\n",
    "pca = PCA(n_components=13)\n",
    "rf = RandomForestClassifier()\n",
    "pipe_pca = Pipeline([('preprocessing', pipe_preprocessing), \n",
    "                     ('pca', pca),\n",
    "                     ('rf', rf)])\n",
    "bas_pca = cross_val_score(pipe_pca, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "mean_bas_pca = np.mean(mean_bas_test)\n",
    "print(f\"Mean Balacend Accuracy Score with 20-splits cross validation: {mean_bas_pca: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNKd83gXB2uy"
   },
   "source": [
    "* ### Summary of Feature Selection\n",
    "As we see from the cross validation result, PCA does not have much influence on the mean accuracy score, but it does help us to make better choice of feature selections and make the model much simpler with basically the same accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOvlHs8OB2uy"
   },
   "source": [
    "# 3. Algorithms & Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_x5yF4JvB2uz"
   },
   "source": [
    "Three appropriate algorithms were chosen for the random search.\n",
    "* **LogisticRegression**: classic classification model w/ or w\\ regularization, requires standardization and normality of features\n",
    "  * C: try to explore the effect of l2 regularization\n",
    "* **RidgeClassifier**: classic classification model with ridge regularization, requires standardization and normality of features\n",
    "* **RandomForestClassifier**: tree based model, does not require standardization or normality of features\n",
    "  * n_estimators: try to explore the effect of number of trees in random forest on accuracy\n",
    "  * max_depth: try to explore the effect of the depth of trees in random forest\n",
    "  * min_samples_leaf: try to explore the effect of the minimun samples leaf\n",
    "* **Metrics**: accuracy_score, as our original data is balanced, and we care more about the precision of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUHCoqyfB2uz",
    "outputId": "b2d91965-bbaa-4865-e1c4-127aae06fcdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 191 candidates, totalling 3820 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                 ('transformer',\n",
       "                                  QuantileTransformer(output_distribution='normal'))])),\n",
       "                ('pca', PCA(n_components=13)),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(max_depth=30, n_estimators=300))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    \"Pass through class, methods are present but do nothing.\"\n",
    "\n",
    "    def fit(self): pass\n",
    "    def score(self): pass\n",
    "\n",
    "pipe_search = Pipeline([\n",
    "    ('prep', pipe_preprocessing),\n",
    "    ('pca', PCA(n_components=13)),\n",
    "    ('clf', DummyEstimator())\n",
    "])\n",
    "\n",
    "search = [\n",
    "            {\n",
    "                'clf': [LogisticRegression()],\n",
    "                'clf__C': np.logspace(0, 5, 50)\n",
    "            },\n",
    "            {\n",
    "                'clf': [RidgeClassifier()]\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                'clf': [RandomForestClassifier()],\n",
    "                'clf__n_estimators': range(50, 400, 50),\n",
    "                'clf__max_depth': [20, 30, 50, 100],\n",
    "                'clf__min_samples_leaf': range(1, 6)\n",
    "            }  \n",
    "         ]\n",
    "clf_algos_rand = GridSearchCV(estimator=pipe_search,\n",
    "                            param_grid=search,\n",
    "                            cv=kfold,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1,\n",
    "                            scoring='accuracy')\n",
    "\n",
    "clf_algos_rand.fit(X_train, y_train)\n",
    "\n",
    "clf_algos_rand.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOYI6GLZB2u0"
   },
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PeYVl-ayB2u0"
   },
   "outputs": [],
   "source": [
    "# final Model\n",
    "pca = PCA(n_components=13)\n",
    "pipe = Pipeline(steps=[('prep',\n",
    "                 Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                 ('transformer',\n",
    "                                  QuantileTransformer(output_distribution='normal'))])),\n",
    "                ('pca', pca),\n",
    "                ('clf',\n",
    "                 RandomForestClassifier(max_depth=30, n_estimators=300))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqxTHJOTB2u0"
   },
   "source": [
    "* ### Accuracy\n",
    "    As we applied final model to the test dataset, the balanced accuracy score is around 0.70, which means our correct classification rate is about 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1YBevkxB2u0",
    "outputId": "e9d2dd63-8344-4733-a46a-c7b3d384a058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6500\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "bas = accuracy_score(y_test, y_pred)\n",
    "print(f\"accuracy_score: {bas: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bi1wVUkB2u0"
   },
   "source": [
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0m94R8zaB2u1"
   },
   "source": [
    "* ### Final Model\n",
    "From the result of cross validation above, we decide our final model is the one with PCA. The Steps in the final pipeline are as follows:\n",
    "    * Standardization and Transformation\n",
    "    * PCA, with n_components = 13\n",
    "    * RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=150)\n",
    "\n",
    "    Note: Random Forest has only hyperparameters and no parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13IP9mkDB2u1"
   },
   "source": [
    "* ### Feature Importance\n",
    "    We still can calculate feature importances, but as we mentioned above in the validation session, the importance with original features is not significant individually, and they obviously have some relationship with other feature, and when they are combined together, they shows some significant importance, so the importance of original features actually is meaningless to our interpretation.\n",
    "    \n",
    "    As we applied PCA to our model to realize this combination and transformation, we can recognize some component with significant importances, while unfortunately, we can no longer know what the new features are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ooJ8HGYB2u1",
    "outputId": "478a7663-bc89-4376-fdfb-e5e0a783ca9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component #0: 26.41%\n",
      "Component #1: 17.50%\n",
      "Component #2: 10.43%\n",
      "Component #3:  7.28%\n",
      "Component #4:  4.85%\n",
      "Component #5:  3.57%\n",
      "Component #6:  2.96%\n",
      "Component #7:  2.66%\n",
      "Component #8:  2.11%\n",
      "Component #9:  1.75%\n",
      "Component #10:  1.54%\n",
      "Component #11:  1.45%\n",
      "Component #12:  1.20%\n"
     ]
    }
   ],
   "source": [
    "# explained variance ration of each component (new feature) after PCA\n",
    "for i, r in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"Component #{i}: {r:>6.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbIqPjd9B2u2"
   },
   "source": [
    "* ### Business Application\n",
    "    Our accuracy score of prediction is about 65%, which looks good to be applied to a auto genre classification for music classification, search and recommendations functionalities of music apps like Spotify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SCstL9rB2u2"
   },
   "source": [
    "* ### Limitations:\n",
    "    * As we applied PCA, we are unable to interpret the importance of real features, but fortunately, in this practical problem, prediction is more important than interpretation.\n",
    "    * Genre Classification is not enough for music recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tv9Z0IRB2u2"
   },
   "source": [
    "* ### Future Directions:\n",
    "    Genre classification with music features is only one of multiple ways to realize the music recommendation fucionalities. We can also use music features and lyrics to do similarity analysis and sentiment analysis, which could provide us recommendation methods from other aspects."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "MSDS699-FinalProject-AprilQianyunLi.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
